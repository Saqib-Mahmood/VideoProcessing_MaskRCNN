{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Day 80.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Saqib-Mahmood/VideoProcessing_MaskRCNN/blob/master/Day_80.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mHlh-jJHOZ1P",
        "colab_type": "text"
      },
      "source": [
        "Import the tensorflow and make sure that we hav selected the GPU as runtime"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mUBerrytOFGg",
        "colab_type": "code",
        "outputId": "41a33edb-32c6-4641-dc31-b2e8054a5a05",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "  raise SystemError('GPU device not found')\n",
        "print('Found GPU at: {}'.format(device_name))"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Found GPU at: /device:GPU:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hzmOGoClOtA-",
        "colab_type": "text"
      },
      "source": [
        "Check the version of GPU"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zg1DVBKDOhAd",
        "colab_type": "code",
        "outputId": "52ed49e4-3a10-420d-aeb5-2e231c37890b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 485
        }
      },
      "source": [
        "from tensorflow.python.client import device_lib\n",
        "device_lib.list_local_devices()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[name: \"/device:CPU:0\"\n",
              " device_type: \"CPU\"\n",
              " memory_limit: 268435456\n",
              " locality {\n",
              " }\n",
              " incarnation: 6434603770968389258, name: \"/device:XLA_CPU:0\"\n",
              " device_type: \"XLA_CPU\"\n",
              " memory_limit: 17179869184\n",
              " locality {\n",
              " }\n",
              " incarnation: 17000654865138613114\n",
              " physical_device_desc: \"device: XLA_CPU device\", name: \"/device:XLA_GPU:0\"\n",
              " device_type: \"XLA_GPU\"\n",
              " memory_limit: 17179869184\n",
              " locality {\n",
              " }\n",
              " incarnation: 14276748561683237411\n",
              " physical_device_desc: \"device: XLA_GPU device\", name: \"/device:GPU:0\"\n",
              " device_type: \"GPU\"\n",
              " memory_limit: 15956161332\n",
              " locality {\n",
              "   bus_id: 1\n",
              "   links {\n",
              "   }\n",
              " }\n",
              " incarnation: 18086225726933650145\n",
              " physical_device_desc: \"device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\"]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MJONGlsCPoty",
        "colab_type": "text"
      },
      "source": [
        "Okay so we verifed that its Tesla K80 GPU. Now we are planning to use Mask RCNN , we are going to install the requirements. \n",
        "\n",
        "Mask R-CNN depends on pycocotools, Let's instal the pycocotools:<br>\n",
        "1) Install Cythin ( which is already installed in colab) <br>\n",
        "2) Clone the repo fo \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r3odz8f0Q_Gw",
        "colab_type": "code",
        "outputId": "f76b04a7-bb73-47ea-c85f-762903fd452b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "!pip install Cython"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: Cython in /usr/local/lib/python3.6/dist-packages (0.29.14)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hrNKk_KoROo7",
        "colab_type": "code",
        "outputId": "0dd1afc6-d8f5-4c6a-f2df-907e920b26c9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!git clone https://github.com/waleedka/coco\n",
        "!pip install -U setuptools\n",
        "!pip install -U wheel\n",
        "!make install -C coco/PythonAPI"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'coco'...\n",
            "remote: Enumerating objects: 904, done.\u001b[K\n",
            "Receiving objects:   0% (1/904)   \rReceiving objects:   1% (10/904)   \rReceiving objects:   2% (19/904)   \rReceiving objects:   3% (28/904)   \rReceiving objects:   4% (37/904)   \rReceiving objects:   5% (46/904)   \rReceiving objects:   6% (55/904)   \rReceiving objects:   7% (64/904)   \rReceiving objects:   8% (73/904)   \rReceiving objects:   9% (82/904)   \rReceiving objects:  10% (91/904)   \rReceiving objects:  11% (100/904)   \rReceiving objects:  12% (109/904)   \rReceiving objects:  13% (118/904)   \rReceiving objects:  14% (127/904)   \rReceiving objects:  15% (136/904)   \rReceiving objects:  16% (145/904)   \rReceiving objects:  17% (154/904)   \rReceiving objects:  18% (163/904)   \rReceiving objects:  19% (172/904)   \rReceiving objects:  20% (181/904)   \rReceiving objects:  21% (190/904)   \rReceiving objects:  22% (199/904)   \rReceiving objects:  23% (208/904)   \rReceiving objects:  24% (217/904)   \rReceiving objects:  25% (226/904)   \rReceiving objects:  26% (236/904)   \rReceiving objects:  27% (245/904)   \rReceiving objects:  28% (254/904)   \rReceiving objects:  29% (263/904)   \rReceiving objects:  30% (272/904)   \rReceiving objects:  31% (281/904)   \rReceiving objects:  32% (290/904), 1.14 MiB | 2.28 MiB/s   \rReceiving objects:  33% (299/904), 1.14 MiB | 2.28 MiB/s   \rReceiving objects:  34% (308/904), 1.14 MiB | 2.28 MiB/s   \rReceiving objects:  35% (317/904), 1.14 MiB | 2.28 MiB/s   \rReceiving objects:  36% (326/904), 1.14 MiB | 2.28 MiB/s   \rReceiving objects:  37% (335/904), 1.14 MiB | 2.28 MiB/s   \rReceiving objects:  38% (344/904), 1.14 MiB | 2.28 MiB/s   \rReceiving objects:  39% (353/904), 1.14 MiB | 2.28 MiB/s   \rReceiving objects:  40% (362/904), 1.14 MiB | 2.28 MiB/s   \rReceiving objects:  41% (371/904), 1.14 MiB | 2.28 MiB/s   \rReceiving objects:  42% (380/904), 1.14 MiB | 2.28 MiB/s   \rReceiving objects:  43% (389/904), 1.14 MiB | 2.28 MiB/s   \rReceiving objects:  44% (398/904), 1.14 MiB | 2.28 MiB/s   \rReceiving objects:  45% (407/904), 1.14 MiB | 2.28 MiB/s   \rReceiving objects:  46% (416/904), 1.14 MiB | 2.28 MiB/s   \rReceiving objects:  47% (425/904), 1.14 MiB | 2.28 MiB/s   \rReceiving objects:  48% (434/904), 1.14 MiB | 2.28 MiB/s   \rReceiving objects:  49% (443/904), 1.14 MiB | 2.28 MiB/s   \rReceiving objects:  50% (452/904), 1.14 MiB | 2.28 MiB/s   \rReceiving objects:  51% (462/904), 1.14 MiB | 2.28 MiB/s   \rReceiving objects:  52% (471/904), 1.14 MiB | 2.28 MiB/s   \rReceiving objects:  53% (480/904), 1.14 MiB | 2.28 MiB/s   \rReceiving objects:  54% (489/904), 1.14 MiB | 2.28 MiB/s   \rReceiving objects:  55% (498/904), 1.14 MiB | 2.28 MiB/s   \rReceiving objects:  56% (507/904), 1.14 MiB | 2.28 MiB/s   \rReceiving objects:  57% (516/904), 1.14 MiB | 2.28 MiB/s   \rReceiving objects:  58% (525/904), 1.14 MiB | 2.28 MiB/s   \rReceiving objects:  59% (534/904), 1.14 MiB | 2.28 MiB/s   \rReceiving objects:  60% (543/904), 1.14 MiB | 2.28 MiB/s   \rReceiving objects:  61% (552/904), 1.14 MiB | 2.28 MiB/s   \rReceiving objects:  62% (561/904), 1.14 MiB | 2.28 MiB/s   \rReceiving objects:  63% (570/904), 1.14 MiB | 2.28 MiB/s   \rReceiving objects:  64% (579/904), 1.14 MiB | 2.28 MiB/s   \rReceiving objects:  65% (588/904), 1.14 MiB | 2.28 MiB/s   \rReceiving objects:  66% (597/904), 1.14 MiB | 2.28 MiB/s   \rReceiving objects:  67% (606/904), 1.14 MiB | 2.28 MiB/s   \rReceiving objects:  68% (615/904), 1.14 MiB | 2.28 MiB/s   \rReceiving objects:  69% (624/904), 1.14 MiB | 2.28 MiB/s   \rReceiving objects:  70% (633/904), 1.14 MiB | 2.28 MiB/s   \rReceiving objects:  71% (642/904), 1.14 MiB | 2.28 MiB/s   \rReceiving objects:  72% (651/904), 1.14 MiB | 2.28 MiB/s   \rReceiving objects:  73% (660/904), 1.14 MiB | 2.28 MiB/s   \rReceiving objects:  74% (669/904), 1.14 MiB | 2.28 MiB/s   \rReceiving objects:  75% (678/904), 1.14 MiB | 2.28 MiB/s   \rReceiving objects:  76% (688/904), 1.14 MiB | 2.28 MiB/s   \rReceiving objects:  77% (697/904), 1.14 MiB | 2.28 MiB/s   \rReceiving objects:  78% (706/904), 1.14 MiB | 2.28 MiB/s   \rReceiving objects:  79% (715/904), 1.14 MiB | 2.28 MiB/s   \rReceiving objects:  80% (724/904), 1.14 MiB | 2.28 MiB/s   \rReceiving objects:  81% (733/904), 1.14 MiB | 2.28 MiB/s   \rReceiving objects:  82% (742/904), 1.14 MiB | 2.28 MiB/s   \rReceiving objects:  83% (751/904), 1.14 MiB | 2.28 MiB/s   \rReceiving objects:  84% (760/904), 1.14 MiB | 2.28 MiB/s   \rReceiving objects:  85% (769/904), 1.14 MiB | 2.28 MiB/s   \rReceiving objects:  86% (778/904), 1.14 MiB | 2.28 MiB/s   \rReceiving objects:  87% (787/904), 1.14 MiB | 2.28 MiB/s   \rremote: Total 904 (delta 0), reused 0 (delta 0), pack-reused 904\u001b[K\n",
            "Receiving objects:  88% (796/904), 1.14 MiB | 2.28 MiB/s   \rReceiving objects:  89% (805/904), 1.14 MiB | 2.28 MiB/s   \rReceiving objects:  90% (814/904), 1.14 MiB | 2.28 MiB/s   \rReceiving objects:  91% (823/904), 1.14 MiB | 2.28 MiB/s   \rReceiving objects:  92% (832/904), 1.14 MiB | 2.28 MiB/s   \rReceiving objects:  93% (841/904), 1.14 MiB | 2.28 MiB/s   \rReceiving objects:  94% (850/904), 1.14 MiB | 2.28 MiB/s   \rReceiving objects:  95% (859/904), 1.14 MiB | 2.28 MiB/s   \rReceiving objects:  96% (868/904), 1.14 MiB | 2.28 MiB/s   \rReceiving objects:  97% (877/904), 1.14 MiB | 2.28 MiB/s   \rReceiving objects:  98% (886/904), 1.14 MiB | 2.28 MiB/s   \rReceiving objects:  99% (895/904), 1.14 MiB | 2.28 MiB/s   \rReceiving objects: 100% (904/904), 1.14 MiB | 2.28 MiB/s   \rReceiving objects: 100% (904/904), 10.38 MiB | 11.58 MiB/s, done.\n",
            "Resolving deltas: 100% (542/542), done.\n",
            "Collecting setuptools\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d9/de/554b6310ac87c5b921bc45634b07b11394fe63bc4cb5176f5240addf18ab/setuptools-41.6.0-py2.py3-none-any.whl (582kB)\n",
            "\u001b[K     |████████████████████████████████| 583kB 8.4MB/s \n",
            "\u001b[31mERROR: datascience 0.10.6 has requirement folium==0.2.1, but you'll have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: setuptools\n",
            "  Found existing installation: setuptools 41.4.0\n",
            "    Uninstalling setuptools-41.4.0:\n",
            "      Successfully uninstalled setuptools-41.4.0\n",
            "Successfully installed setuptools-41.6.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "pkg_resources"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Requirement already up-to-date: wheel in /usr/local/lib/python3.6/dist-packages (0.33.6)\n",
            "make: Entering directory '/content/coco/PythonAPI'\n",
            "# install pycocotools to the Python site-packages\n",
            "python setup.py build_ext install\n",
            "Compiling pycocotools/_mask.pyx because it changed.\n",
            "[1/1] Cythonizing pycocotools/_mask.pyx\n",
            "/usr/local/lib/python3.6/dist-packages/Cython/Compiler/Main.py:369: FutureWarning: Cython directive 'language_level' not set, using 2 for now (Py2). This will change in a later release! File: /content/coco/PythonAPI/pycocotools/_mask.pyx\n",
            "  tree = Parsing.p_module(s, pxd, full_module_name)\n",
            "running build_ext\n",
            "building 'pycocotools._mask' extension\n",
            "creating build\n",
            "creating build/temp.linux-x86_64-3.6\n",
            "creating build/temp.linux-x86_64-3.6/pycocotools\n",
            "creating build/common\n",
            "x86_64-linux-gnu-gcc -pthread -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I/usr/local/lib/python3.6/dist-packages/numpy/core/include -I../common -I/usr/include/python3.6m -c pycocotools/_mask.c -o build/temp.linux-x86_64-3.6/pycocotools/_mask.o -Wno-cpp -Wno-unused-function -std=c99\n",
            "x86_64-linux-gnu-gcc -pthread -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I/usr/local/lib/python3.6/dist-packages/numpy/core/include -I../common -I/usr/include/python3.6m -c ../common/maskApi.c -o build/temp.linux-x86_64-3.6/../common/maskApi.o -Wno-cpp -Wno-unused-function -std=c99\n",
            "\u001b[01m\u001b[K../common/maskApi.c:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[KrleDecode\u001b[m\u001b[K’:\n",
            "\u001b[01m\u001b[K../common/maskApi.c:46:7:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kthis ‘\u001b[01m\u001b[Kfor\u001b[m\u001b[K’ clause does not guard... [\u001b[01;35m\u001b[K-Wmisleading-indentation\u001b[m\u001b[K]\n",
            "       \u001b[01;35m\u001b[Kfor\u001b[m\u001b[K( k=0; k<R[i].cnts[j]; k++ ) *(M++)=v; v=!v; }}\n",
            "       \u001b[01;35m\u001b[K^~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K../common/maskApi.c:46:49:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K...this statement, but the latter is misleadingly indented as if it were guarded by the ‘\u001b[01m\u001b[Kfor\u001b[m\u001b[K’\n",
            "       for( k=0; k<R[i].cnts[j]; k++ ) *(M++)=v; \u001b[01;36m\u001b[Kv\u001b[m\u001b[K=!v; }}\n",
            "                                                 \u001b[01;36m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K../common/maskApi.c:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[KrleFrPoly\u001b[m\u001b[K’:\n",
            "\u001b[01m\u001b[K../common/maskApi.c:165:3:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kthis ‘\u001b[01m\u001b[Kfor\u001b[m\u001b[K’ clause does not guard... [\u001b[01;35m\u001b[K-Wmisleading-indentation\u001b[m\u001b[K]\n",
            "   \u001b[01;35m\u001b[Kfor\u001b[m\u001b[K(j=0; j<k; j++) x[j]=(int)(scale*xy[j*2+0]+.5); x[k]=x[0];\n",
            "   \u001b[01;35m\u001b[K^~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K../common/maskApi.c:165:54:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K...this statement, but the latter is misleadingly indented as if it were guarded by the ‘\u001b[01m\u001b[Kfor\u001b[m\u001b[K’\n",
            "   for(j=0; j<k; j++) x[j]=(int)(scale*xy[j*2+0]+.5); \u001b[01;36m\u001b[Kx\u001b[m\u001b[K[k]=x[0];\n",
            "                                                      \u001b[01;36m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K../common/maskApi.c:166:3:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kthis ‘\u001b[01m\u001b[Kfor\u001b[m\u001b[K’ clause does not guard... [\u001b[01;35m\u001b[K-Wmisleading-indentation\u001b[m\u001b[K]\n",
            "   \u001b[01;35m\u001b[Kfor\u001b[m\u001b[K(j=0; j<k; j++) y[j]=(int)(scale*xy[j*2+1]+.5); y[k]=y[0];\n",
            "   \u001b[01;35m\u001b[K^~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K../common/maskApi.c:166:54:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K...this statement, but the latter is misleadingly indented as if it were guarded by the ‘\u001b[01m\u001b[Kfor\u001b[m\u001b[K’\n",
            "   for(j=0; j<k; j++) y[j]=(int)(scale*xy[j*2+1]+.5); \u001b[01;36m\u001b[Ky\u001b[m\u001b[K[k]=y[0];\n",
            "                                                      \u001b[01;36m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K../common/maskApi.c:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[KrleToString\u001b[m\u001b[K’:\n",
            "\u001b[01m\u001b[K../common/maskApi.c:211:7:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kthis ‘\u001b[01m\u001b[Kif\u001b[m\u001b[K’ clause does not guard... [\u001b[01;35m\u001b[K-Wmisleading-indentation\u001b[m\u001b[K]\n",
            "       \u001b[01;35m\u001b[Kif\u001b[m\u001b[K(more) c |= 0x20; c+=48; s[p++]=c;\n",
            "       \u001b[01;35m\u001b[K^~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K../common/maskApi.c:211:27:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K...this statement, but the latter is misleadingly indented as if it were guarded by the ‘\u001b[01m\u001b[Kif\u001b[m\u001b[K’\n",
            "       if(more) c |= 0x20; \u001b[01;36m\u001b[Kc\u001b[m\u001b[K+=48; s[p++]=c;\n",
            "                           \u001b[01;36m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K../common/maskApi.c:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[KrleFrString\u001b[m\u001b[K’:\n",
            "\u001b[01m\u001b[K../common/maskApi.c:219:3:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kthis ‘\u001b[01m\u001b[Kwhile\u001b[m\u001b[K’ clause does not guard... [\u001b[01;35m\u001b[K-Wmisleading-indentation\u001b[m\u001b[K]\n",
            "   \u001b[01;35m\u001b[Kwhile\u001b[m\u001b[K( s[m] ) m++; cnts=malloc(sizeof(uint)*m); m=0;\n",
            "   \u001b[01;35m\u001b[K^~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K../common/maskApi.c:219:22:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K...this statement, but the latter is misleadingly indented as if it were guarded by the ‘\u001b[01m\u001b[Kwhile\u001b[m\u001b[K’\n",
            "   while( s[m] ) m++; \u001b[01;36m\u001b[Kcnts\u001b[m\u001b[K=malloc(sizeof(uint)*m); m=0;\n",
            "                      \u001b[01;36m\u001b[K^~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K../common/maskApi.c:227:5:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kthis ‘\u001b[01m\u001b[Kif\u001b[m\u001b[K’ clause does not guard... [\u001b[01;35m\u001b[K-Wmisleading-indentation\u001b[m\u001b[K]\n",
            "     \u001b[01;35m\u001b[Kif\u001b[m\u001b[K(m>2) x+=(long) cnts[m-2]; cnts[m++]=(uint) x;\n",
            "     \u001b[01;35m\u001b[K^~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K../common/maskApi.c:227:34:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K...this statement, but the latter is misleadingly indented as if it were guarded by the ‘\u001b[01m\u001b[Kif\u001b[m\u001b[K’\n",
            "     if(m>2) x+=(long) cnts[m-2]; \u001b[01;36m\u001b[Kcnts\u001b[m\u001b[K[m++]=(uint) x;\n",
            "                                  \u001b[01;36m\u001b[K^~~~\u001b[m\u001b[K\n",
            "creating build/lib.linux-x86_64-3.6\n",
            "creating build/lib.linux-x86_64-3.6/pycocotools\n",
            "x86_64-linux-gnu-gcc -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -Wl,-z,relro -Wl,-Bsymbolic-functions -Wl,-z,relro -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 build/temp.linux-x86_64-3.6/pycocotools/_mask.o build/temp.linux-x86_64-3.6/../common/maskApi.o -o build/lib.linux-x86_64-3.6/pycocotools/_mask.cpython-36m-x86_64-linux-gnu.so\n",
            "running install\n",
            "running build\n",
            "running build_py\n",
            "copying pycocotools/mask.py -> build/lib.linux-x86_64-3.6/pycocotools\n",
            "copying pycocotools/cocoeval.py -> build/lib.linux-x86_64-3.6/pycocotools\n",
            "copying pycocotools/__init__.py -> build/lib.linux-x86_64-3.6/pycocotools\n",
            "copying pycocotools/coco.py -> build/lib.linux-x86_64-3.6/pycocotools\n",
            "running install_lib\n",
            "copying build/lib.linux-x86_64-3.6/pycocotools/_mask.cpython-36m-x86_64-linux-gnu.so -> /usr/local/lib/python3.6/dist-packages/pycocotools\n",
            "copying build/lib.linux-x86_64-3.6/pycocotools/mask.py -> /usr/local/lib/python3.6/dist-packages/pycocotools\n",
            "copying build/lib.linux-x86_64-3.6/pycocotools/cocoeval.py -> /usr/local/lib/python3.6/dist-packages/pycocotools\n",
            "copying build/lib.linux-x86_64-3.6/pycocotools/__init__.py -> /usr/local/lib/python3.6/dist-packages/pycocotools\n",
            "copying build/lib.linux-x86_64-3.6/pycocotools/coco.py -> /usr/local/lib/python3.6/dist-packages/pycocotools\n",
            "byte-compiling /usr/local/lib/python3.6/dist-packages/pycocotools/mask.py to mask.cpython-36.pyc\n",
            "byte-compiling /usr/local/lib/python3.6/dist-packages/pycocotools/cocoeval.py to cocoeval.cpython-36.pyc\n",
            "byte-compiling /usr/local/lib/python3.6/dist-packages/pycocotools/__init__.py to __init__.cpython-36.pyc\n",
            "byte-compiling /usr/local/lib/python3.6/dist-packages/pycocotools/coco.py to coco.cpython-36.pyc\n",
            "running install_egg_info\n",
            "Writing /usr/local/lib/python3.6/dist-packages/pycocotools-2.0.egg-info\n",
            "rm -rf build\n",
            "make: Leaving directory '/content/coco/PythonAPI'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cBK_WL-dSiml",
        "colab_type": "code",
        "outputId": "09d5f07a-bb92-4b9a-b1fe-13c39b223147",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "ls /content/coco/PythonAPI"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Makefile  pycocoDemo.ipynb  pycocoEvalDemo.ipynb  \u001b[0m\u001b[01;34mpycocotools\u001b[0m/  setup.py\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z0zekG-nSuq-",
        "colab_type": "text"
      },
      "source": [
        "The above cell clones the coco repository from GitHub and Install build dependencies. And Finally, build and install the coco API library in directory /content/coco/PythonAPI.\n",
        "\n",
        "Now time to clone the Mask_RCNN repo from GitHub ."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9M0EoK66Skwm",
        "colab_type": "code",
        "outputId": "9e4d08f1-c796-431d-901f-c8ab3cef2222",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        }
      },
      "source": [
        "!git clone https://github.com/matterport/Mask_RCNN"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'Mask_RCNN'...\n",
            "remote: Enumerating objects: 956, done.\u001b[K\n",
            "remote: Total 956 (delta 0), reused 0 (delta 0), pack-reused 956\u001b[K\n",
            "Receiving objects: 100% (956/956), 111.81 MiB | 32.55 MiB/s, done.\n",
            "Resolving deltas: 100% (571/571), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_-HLPdt4Tyay",
        "colab_type": "text"
      },
      "source": [
        "Change to the directry ./Mask_RCNN and download the weights from the github !wget https://github.com/matterport/Mask_RCNN/releases/download/v2.0/mask_rcnn_coco.h5"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LXIqqoGfT3PE",
        "colab_type": "code",
        "outputId": "0ea6298c-52bd-4919-9021-0910459348a5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "cd ./Mask_RCNN\n"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/Mask_RCNN\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8EJvsGgDT6cP",
        "colab_type": "code",
        "outputId": "cf9dbfed-8d87-4101-ea8e-83a3b3c1c8ad",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 314
        }
      },
      "source": [
        "!wget https://github.com/matterport/Mask_RCNN/releases/download/v2.0/mask_rcnn_coco.h5"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-11-12 19:27:03--  https://github.com/matterport/Mask_RCNN/releases/download/v2.0/mask_rcnn_coco.h5\n",
            "Resolving github.com (github.com)... 140.82.118.3\n",
            "Connecting to github.com (github.com)|140.82.118.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://github-production-release-asset-2e65be.s3.amazonaws.com/107595270/872d3234-d21f-11e7-9a51-7b4bc8075835?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20191112%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20191112T192703Z&X-Amz-Expires=300&X-Amz-Signature=d5936f88bb9f2fa4e2cdb04904f00100c05d041816b24cdc54875d94780c52e8&X-Amz-SignedHeaders=host&actor_id=0&response-content-disposition=attachment%3B%20filename%3Dmask_rcnn_coco.h5&response-content-type=application%2Foctet-stream [following]\n",
            "--2019-11-12 19:27:03--  https://github-production-release-asset-2e65be.s3.amazonaws.com/107595270/872d3234-d21f-11e7-9a51-7b4bc8075835?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20191112%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20191112T192703Z&X-Amz-Expires=300&X-Amz-Signature=d5936f88bb9f2fa4e2cdb04904f00100c05d041816b24cdc54875d94780c52e8&X-Amz-SignedHeaders=host&actor_id=0&response-content-disposition=attachment%3B%20filename%3Dmask_rcnn_coco.h5&response-content-type=application%2Foctet-stream\n",
            "Resolving github-production-release-asset-2e65be.s3.amazonaws.com (github-production-release-asset-2e65be.s3.amazonaws.com)... 52.217.38.244\n",
            "Connecting to github-production-release-asset-2e65be.s3.amazonaws.com (github-production-release-asset-2e65be.s3.amazonaws.com)|52.217.38.244|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 257557808 (246M) [application/octet-stream]\n",
            "Saving to: ‘mask_rcnn_coco.h5’\n",
            "\n",
            "mask_rcnn_coco.h5   100%[===================>] 245.63M  33.8MB/s    in 7.9s    \n",
            "\n",
            "2019-11-12 19:27:11 (31.1 MB/s) - ‘mask_rcnn_coco.h5’ saved [257557808/257557808]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EX4BoSorT72G",
        "colab_type": "code",
        "outputId": "e4356b59-db46-499c-8039-6c2f537f6ea3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "ls"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[0m\u001b[01;34massets\u001b[0m/  LICENSE      mask_rcnn_coco.h5  README.md         \u001b[01;34msamples\u001b[0m/   setup.py\n",
            "\u001b[01;34mimages\u001b[0m/  MANIFEST.in  \u001b[01;34mmrcnn\u001b[0m/             requirements.txt  setup.cfg\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ysj2Vg0QUhyH",
        "colab_type": "text"
      },
      "source": [
        "Let's copy the sample example from ther report"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qiAt8TpwULRG",
        "colab_type": "code",
        "outputId": "60e2074e-caf7-48c4-f09d-4e8b8709d1ef",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import os\n",
        "import sys\n",
        "import random\n",
        "import math\n",
        "import numpy as np\n",
        "import skimage.io\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Root directory of the project\n",
        "ROOT_DIR =  os.getcwd()  #os.path.abspath(\"../\")\n",
        "\n",
        "# Import Mask RCNN\n",
        "sys.path.append(ROOT_DIR)  # To find local version of the library\n",
        "from mrcnn import utils\n",
        "import mrcnn.model as modellib\n",
        "from mrcnn import visualize\n",
        "# Import COCO config\n",
        "sys.path.append(os.path.join(ROOT_DIR, \"samples/coco/\"))  # To find local version\n",
        "import coco\n",
        "\n",
        "%matplotlib inline \n",
        "\n",
        "# Directory to save logs and trained model\n",
        "MODEL_DIR = os.path.join(ROOT_DIR, \"logs\")\n",
        "\n",
        "# Local path to trained weights file\n",
        "COCO_MODEL_PATH = os.path.join(ROOT_DIR, \"mask_rcnn_coco.h5\")\n",
        "# Download COCO trained weights from Releases if needed\n",
        "if not os.path.exists(COCO_MODEL_PATH):\n",
        "    utils.download_trained_weights(COCO_MODEL_PATH)\n",
        "\n",
        "# Directory of images to run detection on\n",
        "IMAGE_DIR = os.path.join(ROOT_DIR, \"images\")"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xr_fC_G4VLQu",
        "colab_type": "text"
      },
      "source": [
        "<h2>Configurations</h2>\n",
        "\n",
        "\n",
        "We'll be using a model trained on the MS-COCO dataset. The configurations of this model are in the CocoConfig class in coco.py.\n",
        "\n",
        "For inferencing, modify the configurations a bit to fit the task. To do so, sub-class the CocoConfig class and override the attributes you need to change.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "trn-BYsKUvXp",
        "colab_type": "code",
        "outputId": "a70c5957-d88a-4ee0-a366-584f0c270ff9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 918
        }
      },
      "source": [
        "class InferenceConfig(coco.CocoConfig):\n",
        "    # Set batch size to 1 since we'll be running inference on\n",
        "    # one image at a time. Batch size = GPU_COUNT * IMAGES_PER_GPU\n",
        "    GPU_COUNT = 1\n",
        "    IMAGES_PER_GPU = 1\n",
        "\n",
        "config = InferenceConfig()\n",
        "config.display()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Configurations:\n",
            "BACKBONE                       resnet101\n",
            "BACKBONE_STRIDES               [4, 8, 16, 32, 64]\n",
            "BATCH_SIZE                     1\n",
            "BBOX_STD_DEV                   [0.1 0.1 0.2 0.2]\n",
            "COMPUTE_BACKBONE_SHAPE         None\n",
            "DETECTION_MAX_INSTANCES        100\n",
            "DETECTION_MIN_CONFIDENCE       0.7\n",
            "DETECTION_NMS_THRESHOLD        0.3\n",
            "FPN_CLASSIF_FC_LAYERS_SIZE     1024\n",
            "GPU_COUNT                      1\n",
            "GRADIENT_CLIP_NORM             5.0\n",
            "IMAGES_PER_GPU                 1\n",
            "IMAGE_CHANNEL_COUNT            3\n",
            "IMAGE_MAX_DIM                  1024\n",
            "IMAGE_META_SIZE                93\n",
            "IMAGE_MIN_DIM                  800\n",
            "IMAGE_MIN_SCALE                0\n",
            "IMAGE_RESIZE_MODE              square\n",
            "IMAGE_SHAPE                    [1024 1024    3]\n",
            "LEARNING_MOMENTUM              0.9\n",
            "LEARNING_RATE                  0.001\n",
            "LOSS_WEIGHTS                   {'rpn_class_loss': 1.0, 'rpn_bbox_loss': 1.0, 'mrcnn_class_loss': 1.0, 'mrcnn_bbox_loss': 1.0, 'mrcnn_mask_loss': 1.0}\n",
            "MASK_POOL_SIZE                 14\n",
            "MASK_SHAPE                     [28, 28]\n",
            "MAX_GT_INSTANCES               100\n",
            "MEAN_PIXEL                     [123.7 116.8 103.9]\n",
            "MINI_MASK_SHAPE                (56, 56)\n",
            "NAME                           coco\n",
            "NUM_CLASSES                    81\n",
            "POOL_SIZE                      7\n",
            "POST_NMS_ROIS_INFERENCE        1000\n",
            "POST_NMS_ROIS_TRAINING         2000\n",
            "PRE_NMS_LIMIT                  6000\n",
            "ROI_POSITIVE_RATIO             0.33\n",
            "RPN_ANCHOR_RATIOS              [0.5, 1, 2]\n",
            "RPN_ANCHOR_SCALES              (32, 64, 128, 256, 512)\n",
            "RPN_ANCHOR_STRIDE              1\n",
            "RPN_BBOX_STD_DEV               [0.1 0.1 0.2 0.2]\n",
            "RPN_NMS_THRESHOLD              0.7\n",
            "RPN_TRAIN_ANCHORS_PER_IMAGE    256\n",
            "STEPS_PER_EPOCH                1000\n",
            "TOP_DOWN_PYRAMID_SIZE          256\n",
            "TRAIN_BN                       False\n",
            "TRAIN_ROIS_PER_IMAGE           200\n",
            "USE_MINI_MASK                  True\n",
            "USE_RPN_ROIS                   True\n",
            "VALIDATION_STEPS               50\n",
            "WEIGHT_DECAY                   0.0001\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kq-UAaFAVnUb",
        "colab_type": "text"
      },
      "source": [
        "<h2>Create Model and Load Trained Weights </h2>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l5tJgpmxUv2i",
        "colab_type": "code",
        "outputId": "e7b6352d-cc95-4567-ccde-f14e4ad1dac7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 713
        }
      },
      "source": [
        "# Create model object in inference mode.\n",
        "model = modellib.MaskRCNN(mode=\"inference\", model_dir=MODEL_DIR, config=config)\n",
        "\n",
        "# Load weights trained on MS-COCO\n",
        "model.load_weights(COCO_MODEL_PATH, by_name=True)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:2139: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4267: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:2239: The name tf.image.resize_nearest_neighbor is deprecated. Please use tf.compat.v1.image.resize_nearest_neighbor instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/Mask_RCNN/mrcnn/model.py:341: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/Mask_RCNN/mrcnn/model.py:399: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /content/Mask_RCNN/mrcnn/model.py:423: calling crop_and_resize_v1 (from tensorflow.python.ops.image_ops_impl) with box_ind is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "box_ind is deprecated, use box_indices instead\n",
            "WARNING:tensorflow:From /content/Mask_RCNN/mrcnn/model.py:720: The name tf.sets.set_intersection is deprecated. Please use tf.sets.intersection instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/Mask_RCNN/mrcnn/model.py:722: The name tf.sparse_tensor_to_dense is deprecated. Please use tf.sparse.to_dense instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/Mask_RCNN/mrcnn/model.py:772: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:203: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hEdSeptvV1la",
        "colab_type": "text"
      },
      "source": [
        "#Class Names\n",
        "Download the labels.txt and store in the class_name. Or we can we download the COCO Data like below\n",
        "\n",
        "# Load COCO dataset\n",
        "dataset = coco.CocoDataset() <br>\n",
        "dataset.load_coco(COCO_DIR, \"train\")<br>\n",
        "dataset.prepare()\n",
        "\n",
        "# Print class names\n",
        "print(dataset.class_names)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M8YllCKbVsMB",
        "colab_type": "code",
        "outputId": "093bcfd5-6ec8-46ab-f77a-3925cb3a3f03",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 208
        }
      },
      "source": [
        "!wget \"https://raw.githubusercontent.com/nightrome/cocostuff/master/labels.txt\"\n",
        "\n",
        "# load the COCO class labels our YOLO model was trained on\n",
        "labelsPath = os.path.sep.join([os.getcwd(),\"labels.txt\"])\n",
        "LABELS = open(labelsPath).read().strip(':').split(\"\\n\")\n",
        "class_name = []"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-11-12 19:27:48--  https://raw.githubusercontent.com/nightrome/cocostuff/master/labels.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2287 (2.2K) [text/plain]\n",
            "Saving to: ‘labels.txt’\n",
            "\n",
            "\rlabels.txt            0%[                    ]       0  --.-KB/s               \rlabels.txt          100%[===================>]   2.23K  --.-KB/s    in 0s      \n",
            "\n",
            "2019-11-12 19:27:48 (52.2 MB/s) - ‘labels.txt’ saved [2287/2287]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kbq9X92yiOE7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "3d1f10b4-bd03-4923-88e5-95330420d0e5"
      },
      "source": [
        "class_name = []\n",
        "for data in LABELS:\n",
        "  try:\n",
        "    head, tail = data.split(\":\")\n",
        "    class_name.append(tail.strip())\n",
        "  except Exception as e:\n",
        "      print(f\"Error for : {data}\")\n"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Error for : \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7JemKexmpwE0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "340023b0-83f4-4393-e19c-7b639f177783"
      },
      "source": [
        "class_name"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['unlabeled',\n",
              " 'person',\n",
              " 'bicycle',\n",
              " 'car',\n",
              " 'motorcycle',\n",
              " 'airplane',\n",
              " 'bus',\n",
              " 'train',\n",
              " 'truck',\n",
              " 'boat',\n",
              " 'traffic light',\n",
              " 'fire hydrant',\n",
              " 'street sign',\n",
              " 'stop sign',\n",
              " 'parking meter',\n",
              " 'bench',\n",
              " 'bird',\n",
              " 'cat',\n",
              " 'dog',\n",
              " 'horse',\n",
              " 'sheep',\n",
              " 'cow',\n",
              " 'elephant',\n",
              " 'bear',\n",
              " 'zebra',\n",
              " 'giraffe',\n",
              " 'hat',\n",
              " 'backpack',\n",
              " 'umbrella',\n",
              " 'shoe',\n",
              " 'eye glasses',\n",
              " 'handbag',\n",
              " 'tie',\n",
              " 'suitcase',\n",
              " 'frisbee',\n",
              " 'skis',\n",
              " 'snowboard',\n",
              " 'sports ball',\n",
              " 'kite',\n",
              " 'baseball bat',\n",
              " 'baseball glove',\n",
              " 'skateboard',\n",
              " 'surfboard',\n",
              " 'tennis racket',\n",
              " 'bottle',\n",
              " 'plate',\n",
              " 'wine glass',\n",
              " 'cup',\n",
              " 'fork',\n",
              " 'knife',\n",
              " 'spoon',\n",
              " 'bowl',\n",
              " 'banana',\n",
              " 'apple',\n",
              " 'sandwich',\n",
              " 'orange',\n",
              " 'broccoli',\n",
              " 'carrot',\n",
              " 'hot dog',\n",
              " 'pizza',\n",
              " 'donut',\n",
              " 'cake',\n",
              " 'chair',\n",
              " 'couch',\n",
              " 'potted plant',\n",
              " 'bed',\n",
              " 'mirror',\n",
              " 'dining table',\n",
              " 'window',\n",
              " 'desk',\n",
              " 'toilet',\n",
              " 'door',\n",
              " 'tv',\n",
              " 'laptop',\n",
              " 'mouse',\n",
              " 'remote',\n",
              " 'keyboard',\n",
              " 'cell phone',\n",
              " 'microwave',\n",
              " 'oven',\n",
              " 'toaster',\n",
              " 'sink',\n",
              " 'refrigerator',\n",
              " 'blender',\n",
              " 'book',\n",
              " 'clock',\n",
              " 'vase',\n",
              " 'scissors',\n",
              " 'teddy bear',\n",
              " 'hair drier',\n",
              " 'toothbrush',\n",
              " 'hair brush',\n",
              " 'banner',\n",
              " 'blanket',\n",
              " 'branch',\n",
              " 'bridge',\n",
              " 'building-other',\n",
              " 'bush',\n",
              " 'cabinet',\n",
              " 'cage',\n",
              " 'cardboard',\n",
              " 'carpet',\n",
              " 'ceiling-other',\n",
              " 'ceiling-tile',\n",
              " 'cloth',\n",
              " 'clothes',\n",
              " 'clouds',\n",
              " 'counter',\n",
              " 'cupboard',\n",
              " 'curtain',\n",
              " 'desk-stuff',\n",
              " 'dirt',\n",
              " 'door-stuff',\n",
              " 'fence',\n",
              " 'floor-marble',\n",
              " 'floor-other',\n",
              " 'floor-stone',\n",
              " 'floor-tile',\n",
              " 'floor-wood',\n",
              " 'flower',\n",
              " 'fog',\n",
              " 'food-other',\n",
              " 'fruit',\n",
              " 'furniture-other',\n",
              " 'grass',\n",
              " 'gravel',\n",
              " 'ground-other',\n",
              " 'hill',\n",
              " 'house',\n",
              " 'leaves',\n",
              " 'light',\n",
              " 'mat',\n",
              " 'metal',\n",
              " 'mirror-stuff',\n",
              " 'moss',\n",
              " 'mountain',\n",
              " 'mud',\n",
              " 'napkin',\n",
              " 'net',\n",
              " 'paper',\n",
              " 'pavement',\n",
              " 'pillow',\n",
              " 'plant-other',\n",
              " 'plastic',\n",
              " 'platform',\n",
              " 'playingfield',\n",
              " 'railing',\n",
              " 'railroad',\n",
              " 'river',\n",
              " 'road',\n",
              " 'rock',\n",
              " 'roof',\n",
              " 'rug',\n",
              " 'salad',\n",
              " 'sand',\n",
              " 'sea',\n",
              " 'shelf',\n",
              " 'sky-other',\n",
              " 'skyscraper',\n",
              " 'snow',\n",
              " 'solid-other',\n",
              " 'stairs',\n",
              " 'stone',\n",
              " 'straw',\n",
              " 'structural-other',\n",
              " 'table',\n",
              " 'tent',\n",
              " 'textile-other',\n",
              " 'towel',\n",
              " 'tree',\n",
              " 'vegetable',\n",
              " 'wall-brick',\n",
              " 'wall-concrete',\n",
              " 'wall-other',\n",
              " 'wall-panel',\n",
              " 'wall-stone',\n",
              " 'wall-tile',\n",
              " 'wall-wood',\n",
              " 'water-other',\n",
              " 'waterdrops',\n",
              " 'window-blind',\n",
              " 'window-other',\n",
              " 'wood']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jo1mAitZroc3",
        "colab_type": "text"
      },
      "source": [
        "Download a  random photo and we'll use for object detection"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZjivLgBWWCtf",
        "colab_type": "text"
      },
      "source": [
        "Run Object Detection"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T0d_h3so04R2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def random_colors(N):\n",
        "    np.random.seed(1)\n",
        "    colors = [tuple(255 * np.random.rand(3)) for _ in range(N)]\n",
        "    return colors\n",
        "\n",
        "\n",
        "def apply_mask(image, mask, color, alpha=0.5):\n",
        "    \"\"\"apply mask to image\"\"\"\n",
        "    for n, c in enumerate(color):\n",
        "        image[:, :, n] = np.where(\n",
        "            mask == 1,\n",
        "            image[:, :, n] * (1 - alpha) + alpha * c,\n",
        "            image[:, :, n]\n",
        "        )\n",
        "    return image\n",
        "\n",
        "\n",
        "def display_instances(image, boxes, masks, ids, names, scores):\n",
        "    \"\"\"\n",
        "        take the image and results and apply the mask, box, and Label\n",
        "    \"\"\"\n",
        "    n_instances = boxes.shape[0]\n",
        "    colors = random_colors(n_instances)\n",
        "\n",
        "    if not n_instances:\n",
        "        print('NO INSTANCES TO DISPLAY')\n",
        "    else:\n",
        "        assert boxes.shape[0] == masks.shape[-1] == ids.shape[0]\n",
        "\n",
        "    for i, color in enumerate(colors):\n",
        "        if not np.any(boxes[i]):\n",
        "            continue\n",
        "\n",
        "        y1, x1, y2, x2 = boxes[i]\n",
        "        label = names[ids[i]]\n",
        "        score = scores[i] if scores is not None else None\n",
        "        caption = '{} {:.2f}'.format(label, score) if score else label\n",
        "        mask = masks[:, :, i]\n",
        "\n",
        "        image = apply_mask(image, mask, color)\n",
        "        image = cv2.rectangle(image, (x1, y1), (x2, y2), color, 2)\n",
        "        image = cv2.putText(\n",
        "            image, caption, (x1, y1), cv2.FONT_HERSHEY_COMPLEX, 0.7, color, 2\n",
        "        )\n",
        "\n",
        "    return image\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X2gYDKg0jMMz",
        "colab_type": "text"
      },
      "source": [
        "Perform the Object Detection in video"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Th_ZAyCkgY27",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hktfjBKAj-Sx",
        "colab_type": "code",
        "outputId": "c06d3d90-855b-4cc9-f611-5b6e9da63063",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 92
        }
      },
      "source": [
        "from google.colab import files\n",
        "\n",
        "uploaded = files.upload()\n",
        "\n",
        "for fn in uploaded.keys():\n",
        "  print('User uploaded file \"{name}\" with length {length} bytes'.format(\n",
        "      name=fn, length=len(uploaded[fn])))"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-e56ae969-7def-4194-a30e-b799f7d84f16\" name=\"files[]\" multiple disabled />\n",
              "     <output id=\"result-e56ae969-7def-4194-a30e-b799f7d84f16\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving ahahah.mp4 to ahahah.mp4\n",
            "User uploaded file \"ahahah.mp4\" with length 8476383 bytes\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b8IQFXZE062-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import cv2\n",
        "execution_path = os.getcwd()\n",
        "cap=cv2.VideoCapture(0) # 0 stands for very first webcam attach\n",
        "filename= os.path.join(execution_path, 'output.avi') #[place were i stored my output file]\n",
        "codec=cv2.VideoWriter_fourcc('M','J','P','G')#fourcc stands for four character code\n",
        "framerate=10\n",
        "resolution=(640,480)\n",
        "# Default resolution of the frame is obtained.The default resolution is system dependent.\n",
        "frame_width = int(cap.get(3))\n",
        "frame_height = int(cap.get(4))\n",
        "\n",
        "VideoFileOutput=cv2.VideoWriter(filename,cv2.VideoWriter_fourcc('M','J','P','G'), 10, (frame_width,frame_height))\n",
        "frames = []\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ys3q_wP0CmK0",
        "colab_type": "text"
      },
      "source": [
        "Run Object Prediciton"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jDfZMhQEkc9a",
        "colab_type": "code",
        "outputId": "7839f584-4f0b-41f1-88bd-f2607d71a103",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "while True:\n",
        "    # read the next frame from the file\n",
        "    (found, img) = cap.read()\n",
        "\n",
        "    # if the frame was not grabbed, then we have reached the end\n",
        "    # of the stream\n",
        "    if not found:\n",
        "        break\n",
        "\n",
        "    frames.append(img)\n",
        "    predict = model.detect(frames, verbose=0)\n",
        "    if len(frames) != 1:\n",
        "      print(\"Error in framges\")\n",
        "    print(f\"Frames size is : {len(frames)}\")\n",
        "    for i, item in enumerate(zip(frames, predict)):\n",
        "        frame = item[0]\n",
        "        r = item[1]\n",
        "        frame = display_instances(\n",
        "                frame, r['rois'], r['masks'], r['class_ids'], class_name, r['scores']\n",
        "            )\n",
        "\n",
        "# check if the video writer is None\n",
        "    # write the output frame to disk\n",
        "\n",
        "    VideoFileOutput.write(frame)\n",
        "    cv2.imshow('live_detection',frame)\n",
        "    frames = []\n",
        "    if cv2.waitKey(25) & 0xFF==ord('q'):\n",
        "            break\n",
        "    # release the file pointers\n",
        "        # Clear the frames array to start the next batch\n",
        "\n",
        "print(\"[INFO] cleaning up...\")\n",
        "cv2.destroyAllWindows()\n",
        "cap.release()\n",
        "VideoFileOutput.release()\n"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[INFO] cleaning up...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GNcYRYMYEOPK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CVIiNxngp5Lu",
        "colab_type": "text"
      },
      "source": [
        "We have to arrange all the fi"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R3XH8X0dnamB",
        "colab_type": "code",
        "outputId": "9c293bb8-23b7-4e33-f355-0421cfb45bb9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "ls"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ahahah.mp4  labels.txt   mask_rcnn_coco.h5  README.md         setup.cfg\n",
            "\u001b[0m\u001b[01;34massets\u001b[0m/     LICENSE      \u001b[01;34mmrcnn\u001b[0m/             requirements.txt  setup.py\n",
            "\u001b[01;34mimages\u001b[0m/     MANIFEST.in  output.avi         \u001b[01;34msamples\u001b[0m/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iStbwr5HtQYr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import files\n",
        "\n",
        "files.download('output.avi')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6QkNL_3-G8Xk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "1683d541-51d9-4141-d2d5-c1057a0e4078"
      },
      "source": [
        "pwd"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/Mask_RCNN'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Me9ETOzLISjx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "files.download('/content/Mask_RCNN/images/3800883468_12af3c0b50_z.jpg')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nM41yfK0IfIi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}